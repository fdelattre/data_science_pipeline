{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préliminaires\n",
    "\n",
    "## Lecture et description du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'default-of-credit-card-clients-dataset.zip'\n",
    "target    = 'default.payment.next.month'\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer=file_path)\n",
    "print(df.shape)\n",
    "df = df.drop('ID', axis=1)\n",
    "print(df[target].value_counts() / len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type des features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcourir chaque colonne du fichier\n",
    "\n",
    "- Identifier le type\n",
    "- Compter le nombre de valeurs uniques N_u\n",
    "    - Si numérique :\n",
    "        - Si N_u < 10 : variable catégorielle\n",
    "        - Si N_u >= 10 : à investiguer\n",
    "        - Si N_u > 50 : variable continue\n",
    "    - Si character :\n",
    "        - Si N_u < 10 : variable catégorielle\n",
    "        - Si N_u >= 10 : à investiguer\n",
    "        - Si N_u > 50 : variable textuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features  = df.drop(target, axis=1).columns\n",
    "\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "other_features = []\n",
    "to_investigate = []\n",
    "\n",
    "for feature in raw_features:\n",
    "    N_u = len(df[feature].unique())\n",
    "    feature_type = df[feature].dtype\n",
    "    if feature_type == np.float64 or feature_type == np.int64:\n",
    "        if(N_u) < 10:\n",
    "            categorical_features.append([feature, N_u])\n",
    "        if(N_u >= 10 and N_u <50):\n",
    "            to_investigate.append([feature, N_u])\n",
    "        if(N_u >= 50):\n",
    "            numerical_features.append([feature, N_u])\n",
    "    else:\n",
    "        other_features.append([feature, N_u])\n",
    "            \n",
    "        \n",
    "print(\"categorical features (<10 unique values):{}\".format(categorical_features))\n",
    "print(\"features to investigate :{}\".format(to_investigate))\n",
    "print(\"numerical features (more than 50 unique values):{}\".format(numerical_features))\n",
    "print(\"other features :{}\".format(other_features))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_categorize = ['SEX', 'EDUCATION', 'MARRIAGE', \n",
    "                          'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for feature in features_to_categorize:\n",
    "    df[feature] = df[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[.2, .4, .6, .8]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['category']).describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making correlation coefficients pair plot of all feature in order to identify degenrate features\n",
    "plt.figure(figsize=(25,25))\n",
    "ax = plt.axes()\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, vmax=1,vmin=-1, square=True, annot=True, cmap='Spectral',linecolor=\"white\", linewidths=0.01, ax=ax)\n",
    "ax.set_title('Correlation Coefficient Pair Plot',fontweight=\"bold\", size=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse descriptive\n",
    "\n",
    "Le code suivant génère 2 fichiers pdf :\n",
    "- numerical_features_plots.pdf : les distributions de chaque variable numérique conditionnellement à la cible\n",
    "- categorical_features_plots.pdf : les barplots des variables categorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('category').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, figsize=(20, 12))\n",
    "\n",
    "AGE_bin = pd.qcut(df['AGE'], 10, duplicates='drop', labels=None)\n",
    "LIMIT_BAL_bin = pd.qcut(df['LIMIT_BAL'], 10, duplicates='drop', labels=None)\n",
    "PAY_AMT1_bin = pd.qcut(df['PAY_AMT1'], 10, duplicates='drop', labels=None)\n",
    "\n",
    "sns.barplot(x = PAY_AMT1_bin,\n",
    "            y = df['BILL_AMT1'],\n",
    "            hue = df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Variables numériques\n",
    "# Génère un fichier pdf\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pp = PdfPages('numerical_features_plots.pdf')\n",
    "\n",
    "for feature in df.select_dtypes(np.number).columns:\n",
    "    sns.distplot(df[feature][df[target] == 1])\n",
    "    sns.distplot(df[feature][df[target] == 0])\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables catégorielles\n",
    "sns.set_style(\"whitegrid\")\n",
    "pp = PdfPages('categorical_features_plots.pdf')\n",
    "\n",
    "for feature in df.select_dtypes('category').columns:\n",
    "    crs_tab = pd.crosstab(df[feature], df[target]).stack().reset_index().rename(columns={0:'value'})\n",
    "    sns.barplot(x=crs_tab[feature], y=crs_tab.value, hue=crs_tab[target])\n",
    "    pp.savefig()\n",
    "    plt.show()\n",
    "    \n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', target]], hue=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['BILL_AMT1', 'PAY_AMT1', 'PAY_0', 'BILL_AMT2', 'PAY_AMT2', 'PAY_2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "(fig, subplots) = plt.subplots(ncols=4, figsize=(15, 8))\n",
    "\n",
    "n_components = 2\n",
    "perplexities = [5, 30, 50, 100]\n",
    "\n",
    "df_samp = df.sample(frac=0.2)\n",
    "\n",
    "red = df_samp[target] == 0\n",
    "green = df_samp[target] == 1\n",
    "\n",
    "\n",
    "\n",
    "for i, perplexity in enumerate(perplexities):\n",
    "    ax = subplots[i]\n",
    "    ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "    \n",
    "    tsne = TSNE(n_components=n_components, init='random', random_state=0, perplexity=perplexity)\n",
    "    Y = tsne.fit_transform(df_samp)\n",
    "    \n",
    "    ax.scatter(Y[red, 0], Y[red, 1], c=\"r\")\n",
    "    ax.scatter(Y[green, 0], Y[green, 1], c=\"g\")\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfo des données\n",
    "\n",
    "Données catégorielles sont transformées en 0/1\n",
    "Données numériques transformées \n",
    "\n",
    "- f:x => sig(x)*log(1+abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_transfo = [ 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "# \n",
    "# for feature in features_transfo:\n",
    "#     df[feature] = df[feature].apply(lambda x: np.sign(x)*np.log(1+np.abs(x)))\n",
    "# \n",
    "# df[features_transfo].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression de variables inutiles, redondantes ou fortement corrélées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = ['BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6']\n",
    "\n",
    "df = df.drop(features_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroupement de modalités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDUCATION 0,4,5,6 ==> 0\n",
    "# MARRIAGE 0,3 ==> AUTRE\n",
    "# PAY_0 > 4 ==> 0\n",
    "# PAY_2 = 1,4,5,6,7,8 ==> 0\n",
    "# PAY_3 = 1,4,5,6,7,8 ==> 0\n",
    "# PAY_4 = 1,4,5,6,7,8 ==> 0\n",
    "# PAY_5 = 4,5,6,7,8 ==> 0\n",
    "# PAY_6 = 4,5,6,7,8 ==> 0\n",
    "\n",
    "df.loc[df['EDUCATION']== 0,'EDUCATION'] = 2\n",
    "df.loc[df['EDUCATION'].isin([4,5,6]),'EDUCATION'] = 4\n",
    "\n",
    "df.loc[df['MARRIAGE'].isin([0,3]), 'MARRIAGE'] = 2\n",
    "df.loc[df['PAY_0'].isin([5,6,7,8]),'PAY_0'] = 0\n",
    "df.loc[df['PAY_2'].isin([1,4,5,6,7,8]),'PAY_2'] = 0\n",
    "df.loc[df['PAY_3'].isin([1,4,5,6,7,8]),'PAY_3'] = 0\n",
    "df.loc[df['PAY_4'].isin([1,4,5,6,7,8]),'PAY_4'] = 0\n",
    "df.loc[df['PAY_5'].isin([4,5,6,7,8]),'PAY_5'] = 0\n",
    "df.loc[df['PAY_6'].isin([4,5,6,7,8]),'PAY_6'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrétisation des variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_discretize = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "# \n",
    "# for feature in features_to_discretize:\n",
    "#     df[feature] = pd.qcut(df[feature], 5, duplicates='drop', labels=False)\n",
    "#     df[feature] = df[feature].astype('category')\n",
    "#     \n",
    "# df[features_to_discretize].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de nouvelles variables\n",
    "\n",
    "Ici on peut lire et ajouter des embeddings FastText et créer des combinaisons de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BILL_AMT1_DIV_LIMIT_BAL'] = df['BILL_AMT1'] / df['LIMIT_BAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PAY_AMT2_DIV_BILL_AMT1.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "X_train_train, X_train_test = np.split(df.sample(frac = 1), [20000])\n",
    "print(len(X_train_train))\n",
    "print(len(X_train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_train[target].value_counts() / len(X_train_train))\n",
    "print(X_train_test[target].value_counts() / len(X_train_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusion d'outliers sur X_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from scipy import stats\n",
    "\n",
    "features_for_outlier_detection = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "outliers_fraction = 0.10\n",
    "clf = EllipticEnvelope(contamination=outliers_fraction)\n",
    "clf.fit(X_train_train[features_for_outlier_detection])\n",
    "scores_pred = clf.decision_function(X_train_train[features_for_outlier_detection])\n",
    "y_pred = clf.predict(X_train_train[features_for_outlier_detection])\n",
    "threshold = stats.scoreatpercentile(scores_pred, 100 * outliers_fraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier = X_train_train[y_pred == -1]\n",
    "\n",
    "print(df_outlier[target].value_counts() / len(df_outlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_train = X_train_train[y_pred == 1 ]\n",
    "X_train_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, RobustScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "subset = df.columns[df.columns != target]\n",
    "\n",
    "# Commenter pour utiliser toutes les features\n",
    "\n",
    "# subset = best_subset\n",
    "\n",
    "y = X_train_train[target]\n",
    "X = X_train_train[subset]\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "clf = XGBClassifier(n_estimators = 200, max_depth = 3, reg_alpha = 0.001)\n",
    "\n",
    "scale_gbm = Pipeline([\n",
    "    ('scale', scaler),\n",
    "    ('gbm', clf)])\n",
    "\n",
    "\n",
    "scores = cross_val_score(scale_gbm, X, y, cv=5, scoring= 'roc_auc')\n",
    "\n",
    "scale_gbm.fit(X=X, y=y)\n",
    "\n",
    "print(scores)\n",
    "print('AUC moyen : {}\\nstd AUC : {}\\nGini moyen : {}'.format(np.average(scores), np.std(scores), 2*np.average(scores) -1 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = scale_gbm.named_steps.gbm.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 15))\n",
    "importance_df = pd.DataFrame({'feature' : subset[indices],'imp' : importances[indices]})\n",
    "sns.barplot(x='imp', y='feature', data= importance_df)\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "best_subset = subset[indices][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "   \n",
    "    \n",
    "def evaluate_delta(model, test_df, features, target_feature, iterations = 100):\n",
    "    # This function evaluates the Gini variation according to the challenge rules\n",
    "    # The test set is divided into private (60%) and public (40%) \n",
    "    \n",
    "    # we will try to evaluate through multiple iterations\n",
    "    # return a list of length iterations containing the absolute value of deltas\n",
    "    \n",
    "    deltas = []\n",
    "    ginis_public  = []\n",
    "    ginis_private  = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        # Split\n",
    "        public_test, private_test = np.split(test_df.sample(frac = 1), [int(len(test_df)*.4)])\n",
    "        \n",
    "        # Prediction on public\n",
    "        probas_public = model.predict_proba(public_test[features])\n",
    "        actual_public = public_test[target_feature]\n",
    "        \n",
    "        # Prediction on private\n",
    "        probas_private = model.predict_proba(private_test[features])\n",
    "        actual_private = private_test[target_feature]\n",
    "        \n",
    "        # Gini estimation\n",
    "        gini_public = 2*roc_auc_score(actual_public, probas_public[:,1]) - 1\n",
    "        gini_private = 2*roc_auc_score(actual_private, probas_private[:,1]) - 1\n",
    "        \n",
    "        ginis_public.append(gini_public)\n",
    "        ginis_private.append(gini_private)\n",
    "        \n",
    "        # Delta \n",
    "        delta = (gini_private / gini_public)-1\n",
    "        deltas.append(np.abs(delta))\n",
    "    \n",
    "    return deltas, ginis_public, ginis_private\n",
    "    \n",
    "\n",
    "deltas, ginis_public, ginis_private = evaluate_delta(scale_gbm, X_train_test, subset, target, iterations=100)  \n",
    "\n",
    "print('Gini public moyen : {}'.format(np.mean(ginis_public)))\n",
    "print('Gini private moyen : {}'.format(np.mean(ginis_private)))\n",
    "print('delta moyen : {} - delta std : {}'.format(np.mean(deltas), np.std(deltas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lift_matrix(model, test_df, features, target, quantiles = 10):\n",
    "    \n",
    "    proba_test = model.predict_proba(test_df[subset])[:,1]\n",
    "    \n",
    "    df_probas = pd.DataFrame({\n",
    "        'proba':proba_test, \n",
    "        'target':X_train_test[target]})\n",
    "    \n",
    "    df_probas['decile'] = pd.qcut(df_probas['proba'], quantiles, labels = False)\n",
    "    \n",
    "    decile_size = df_probas.groupby('decile').size()\n",
    "    decile_min  = df_probas.groupby('decile')['proba'].min()\n",
    "    decile_max  = df_probas.groupby('decile')['proba'].max()\n",
    "    decile_sum_target = df_probas.groupby('decile')['target'].sum()\n",
    "    \n",
    "    df_results = pd.DataFrame({\n",
    "        'size' : decile_size,\n",
    "        'min' : decile_min,\n",
    "        'max' : decile_max,\n",
    "        'sum_target' : decile_sum_target})\n",
    "        \n",
    "    df_results = df_results.assign(ratio = lambda df: df['sum_target'] / df['size'])\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "lift_matrix = evaluate_lift_matrix(scale_gbm, X_train_test, subset, target)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.barplot(x=lift_matrix.index[::-1], y=lift_matrix.ratio)\n",
    "overall_ratio = X_train_test[target].sum() / len(X_train_test)\n",
    "plt.axhline(y=overall_ratio, color='r', linestyle='--')\n",
    "plt.plot()\n",
    "lift_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauvegarde dans un dossier 'save':\n",
    "- X_train_train\n",
    "- X_train_testpublic\n",
    "- X_train_testpriv\n",
    "- le modèle\n",
    "- subset\n",
    "- les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'save'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('save/foo.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
